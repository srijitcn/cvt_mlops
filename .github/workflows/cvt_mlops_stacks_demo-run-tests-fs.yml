name: Feature and Training Integration Tests for cvt_mlops_stacks_demo
on:
  workflow_dispatch:
  pull_request:

defaults:
  run:
    working-directory: ./cvt_mlops_stacks_demo/

env:
  ARM_TENANT_ID: ${{ secrets.STAGING_AZURE_SP_TENANT_ID }}
  ARM_CLIENT_ID: ${{ secrets.STAGING_AZURE_SP_APPLICATION_ID }}
  ARM_CLIENT_SECRET: ${{ secrets.STAGING_AZURE_SP_CLIENT_SECRET }}

concurrency: cvt_mlops_stacks_demo-feature-training-integration-test-staging

jobs:
  unit_tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
        with:
          python-version: 3.8
      # Feature store tests bring up a local Spark session, so Java is required.
      - uses: actions/setup-java@v2
        with:
          distribution: 'temurin'
          java-version: '11'
      - name: Install dependencies
        run: |
            python -m pip install --upgrade pip
            pip install -r requirements.txt
            pip install -r ../test-requirements.txt
      - name: Run tests with pytest
        run: |
            pytest

  integration_test:
    needs: unit_tests
    runs-on: ubuntu-22.04
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3
      - uses: databricks/setup-cli@main
      - name: Validate Bundle For Test Deployment Target in Staging Workspace
        id: validate
        run: |
          databricks bundle validate -t test
      - name: Deploy Bundle to Test Deployment Target in Staging Workspace
        id: deploy
        run: |
          databricks bundle deploy -t test
      - name: Run Feature Engineering Workflow for Test Deployment Target in Staging Workspace
        id: feature_engineering
        run: |
          databricks bundle run write_feature_table_job -t test
      - name: Run Training Workflow for Test Deployment Target in Staging Workspace
        id: training
        run: |
          databricks bundle run model_training_job -t test
